This module provides a stepwise framework for setting up and running analyses. The library covers complex operations involving multiple steps, with multiple inputs supported. It supports multiple data types and dynamic but controllable caching. The analysis workflow is designed to be modular and extensible, allowing users to easily add new analysis types or customize existing ones. Specific common analysis operations are defined in `pypatchy.patchy.analysis_lib`.

# analysis_data.py
Defines a flexible set of data-container classes used in the PyPatchy analysis pipeline, allowing simulation outputs, observables, raw trajectory data, and intermediate results to be stored, merged, cached, sliced, and validated in a consistent way. A shared abstract base class (`PipelineData`) specifies the interface for time-indexed data, while concrete subclasses handle pandas DataFrames, arbitrary Python objects, and raw trajectory objects. The module also implements merging logic with overlap detection, caching via HDF5 or pickle, and custom exceptions for missing or conflicting timepoint data, forming the structural backbone for downstream analysis tools.

# analysis_pipeline.py
Defines the directed-graph-based framework used to build, connect, and execute multi-step analysis workflows in PyPatchy. An `AnalysisPipeline` contains named analysis steps as nodes and data-flow connections as edges, enforcing acyclicity while supporting complex dependency structures, aggregation steps, timestep propagation, and automatic consistency checks. The class provides rich utilities for adding and extending pipelines, querying ancestors/descendants, merging pipelines, validating update intervals, and even generating SVG visualizations of the pipeline graph. Overall, it serves as the orchestration layer for modular, configurable post-simulation analysis. 

# analysis_pipeline_step.py
Defines the abstract interface and base classes for individual steps within a PyPatchy analysis pipeline. Each `AnalysisPipelineStep` encapsulates a named operation with specified input/output timestep intervals, methods for executing the step, caching its output, and declaring the type of data it produces. Specialized subclasses include `AnalysisPipelineHead` (steps that originate raw simulation data) and `AggregateAnalysisPipelineStep` (steps that combine results across simulation ensembles). The module also provides utilities for parameter filtering, cache-file naming, and minimal SVG-based visualization support used by the pipeline drawing system.

# analyzable.py
Defines the abstract base class for any object that can participate in a PyPatchy analysis pipelineâ€”most notably [simulation ensembles](../patchy/simulation_ensemble.py). It manages an associated `AnalysisPipeline`, tracks cached analysis results keyed by (step, parameter set), and provides mechanisms to load, merge, extend, link, or replace pipelines. The class also defines utilities for checking missing data, determining whether cached results can be reused, and delegating status reporting, caching behavior, and logging to subclasses. In practice, `Analyzable` serves as the integration layer between raw simulations and the modular analysis-pipeline system.

